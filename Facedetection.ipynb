{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 217 101 101\n",
      "296 217 101 101\n",
      "296 216 101 101\n",
      "296 218 101 101\n",
      "296 216 101 101\n",
      "296 216 101 101\n",
      "295 216 101 101\n",
      "294 216 101 101\n",
      "296 216 101 101\n",
      "295 216 101 101\n",
      "296 217 101 101\n",
      "296 216 101 101\n",
      "294 216 101 101\n",
      "295 217 101 101\n",
      "296 217 101 101\n",
      "295 216 101 101\n",
      "295 216 101 101\n",
      "294 216 101 101\n",
      "295 216 101 101\n",
      "296 216 101 101\n",
      "297 216 101 101\n",
      "295 216 101 101\n",
      "296 217 101 101\n",
      "297 216 101 101\n",
      "295 216 101 101\n",
      "296 217 101 101\n",
      "296 216 101 101\n",
      "296 216 101 101\n",
      "296 217 101 101\n",
      "296 216 101 101\n",
      "296 216 101 101\n",
      "296 216 101 101\n",
      "296 216 101 101\n",
      "296 216 101 101\n",
      "295 216 101 101\n",
      "296 216 101 101\n",
      "298 216 101 101\n",
      "299 214 101 101\n",
      "299 212 101 101\n",
      "298 211 101 101\n",
      "300 201 101 101\n",
      "299 197 101 101\n",
      "299 187 101 101\n",
      "299 167 101 101\n",
      "300 161 101 101\n",
      "302 157 101 101\n",
      "300 156 101 101\n",
      "303 160 101 101\n",
      "281 140 152 152\n",
      "1\n",
      "devesh\n",
      "281 143 152 152\n",
      "1\n",
      "devesh\n",
      "283 150 152 152\n",
      "1\n",
      "devesh\n",
      "289 156 152 152\n",
      "1\n",
      "devesh\n",
      "292 157 152 152\n",
      "1\n",
      "devesh\n",
      "292 159 152 152\n",
      "1\n",
      "devesh\n",
      "290 158 152 152\n",
      "1\n",
      "devesh\n",
      "292 159 152 152\n",
      "1\n",
      "devesh\n",
      "299 158 152 152\n",
      "1\n",
      "devesh\n",
      "293 160 152 152\n",
      "1\n",
      "devesh\n",
      "296 159 152 152\n",
      "1\n",
      "devesh\n",
      "299 160 152 152\n",
      "1\n",
      "devesh\n",
      "295 159 152 152\n",
      "1\n",
      "devesh\n",
      "294 153 152 152\n",
      "1\n",
      "devesh\n",
      "316 160 101 101\n",
      "317 161 101 101\n",
      "319 161 101 101\n",
      "319 163 101 101\n"
     ]
    }
   ],
   "source": [
    "face_cascade= cv2.CascadeClassifier('Cascades/data/haarcascade_frontalface_alt2.xml')\n",
    "eye_cascade=cv2.CascadeClassifier('Cascades/data/haarcascade_eye.xml')\n",
    "\n",
    "recognizer=cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read(\"trainner.yml\")\n",
    "\n",
    "labels = {\"person_name\":2}\n",
    "with open(\"labels.pickle\", 'rb') as f:\n",
    "    og_labels = pickle.load(f)\n",
    "    labels={v:k for k,v in og_labels.items()}\n",
    "cap =cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    gray =cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces= face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "    for(x,y,w,h) in faces:\n",
    "        print(x,y,w,h) \n",
    "        roi_gray= gray[y:y+h, x:x+w] #(ycord_start, ycord_end) \n",
    "        roi_color= frame[y:y+h, x:x+w]\n",
    "        \n",
    "        #recognizer - Deep learned model predict keras tenserflow pytorch scikit learn                        \n",
    "        id_,conf=recognizer.predict(roi_gray)\n",
    "        if conf>=45 and conf <=85:\n",
    "            print(id_)\n",
    "            print(labels[id_])\n",
    "            font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "            name=labels[id_]\n",
    "            color=(255,255,255)\n",
    "            stroke=2\n",
    "            cv2.putText(frame, name, (x,y), font, 1, color, stroke, cv2.LINE_AA)\n",
    "        img_item = \"1.png\"\n",
    "        cv2.imwrite(img_item, roi_color)\n",
    "        \n",
    "        color=(255,0,0)\n",
    "        stroke=2\n",
    "        end_cord_x=x+w\n",
    "        end_cord_y=y+h\n",
    "        cv2.rectangle(frame,(x,y),(end_cord_x, end_cord_y),color, stroke)\n",
    "        eyes= eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "        \n",
    "        \n",
    "        #display the result frame\n",
    "        cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
